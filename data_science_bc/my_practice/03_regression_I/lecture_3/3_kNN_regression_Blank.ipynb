{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1769a6",
   "metadata": {},
   "source": [
    "# $k$ Nearest Neighbors regression\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Explain the difference between parametric and non-parametric methods.\n",
    "- Introduce the $k$ Nearest Neighbors regression algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f515b56",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c651e",
   "metadata": {},
   "source": [
    "## Parametric vs. Non-Parametric\n",
    "\n",
    "The terms \"parametric\" and \"non-parametric\" do not have standardized definitions.\n",
    "\n",
    "We have already explained the parametric regression framework:  a model or \"hypothesis class\" is a family of functions $f_\\beta$ parameterized by $\\beta$.  Generally $\\beta$ is a vector of a fixed length.  We fit a model by finding the value of $\\beta$ which minimize a loss function which compares model outputs $f(x_i)$ to actual observed outputs $y_i$.\n",
    "\n",
    "By contrast a **non-parametric** model has a hypothesis class of functions which are not easily parameterized by a vector of a fixed length.  \n",
    "\n",
    "Our first example of a non-parametric model is $k$ Nearest Neighbors regression (kNN for short)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbe1e1",
   "metadata": {},
   "source": [
    "## kNN Regression\n",
    "\n",
    "Given data of the form $(\\vec{x}_i, y_i)$ with $\\vec{x}_i \\in \\mathbb{R}^p$ and $y_i \\in \\mathbb{R}$:\n",
    "\n",
    "* We select a whole number $k$.  \n",
    "    * This is our first example of a **hyperparameter**:  our choice of $k$ defines the hypothesis class rather than being a parameter which we alter when fitting the model.\n",
    "* Given any $\\vec{x} \\in \\mathbb{R}^p$ we define $f(\\vec{x})$ to be the mean of $y_i$ for the $k$ training inputs $\\vec{x}_i$ which are nearest to $x$.\n",
    "\n",
    "That is it!\n",
    "\n",
    "Some notes about the model:\n",
    "* If the input $x$ is \"far\" from the original training data kNN will generalize poorly.\n",
    "* Although Euclidean distance is the most common choice, other metrics can be used.\n",
    "* You don't have to use the mean:  you could use a weighted mean, the median, etc.\n",
    "* It is common to first scale your data so that the features on the largest scale do not dominate.  This can sometimes destroy \"signal\" so be sure to check that this choice improves cross-validation performance.\n",
    "* It is computationally intensive to actually find the nearest $k$ training points, so in practice the neighbors found are approximately correct but may not be the true $k$ nearest neighbors. \n",
    "\n",
    "### In `sklearn`\n",
    "\n",
    "$k$ nearest neighbors regression can be performed with `sklearn`'s `KNeighborsRegressor` model object, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb9579",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "## import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af26950e",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "np.random.seed(216)\n",
    "X = 3*np.random.normal(size = (100,1))\n",
    "y = (np.sin(X) + 0.2*np.random.normal(size = X.shape)).reshape(-1)\n",
    "\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbccf22",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "## make model objects\n",
    "knr_2 = \n",
    "knr_10 = \n",
    "\n",
    "## Fit the models\n",
    "\n",
    "\n",
    "## Plot the fits\n",
    "fig,ax = plt.subplots(1, 2, figsize = (12,5), sharex=True, sharey=True)\n",
    "\n",
    "ax[0].scatter(X, \n",
    "              y,\n",
    "              alpha = .3,\n",
    "              label=\"Training Data\")\n",
    "ax[1].scatter(X, \n",
    "              y,\n",
    "              alpha = .3,\n",
    "              label=\"Training Data\")\n",
    "\n",
    "ax[0].plot(np.linspace(np.min(X)-1,np.max(X)+1, 300).reshape(-1,1),\n",
    "           knr_2.predict(np.linspace(np.min(X)-1,np.max(X)+1, 300).reshape(-1,1)),\n",
    "           'k',\n",
    "           label=\"KNR\")\n",
    "\n",
    "ax[0].set_title('$k = 2$')\n",
    "\n",
    "ax[1].plot(np.linspace(np.min(X)-1,np.max(X)+1, 300).reshape(-1,1),\n",
    "           knr_10.predict(np.linspace(np.min(X)-1,np.max(X)+1, 300).reshape(-1,1)),\n",
    "           'k',\n",
    "           label=\"KNR\")\n",
    "\n",
    "ax[1].set_title('$k = 10$')\n",
    "\n",
    "ax[0].legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3983ece7",
   "metadata": {},
   "source": [
    "Notice that kNN gives piecewise constant predictions.  These become constant once you get outside of the interval where we had training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d565b8",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd≈ës Institute Data Science Boot Camp by Steven Gubkin.\n",
    "\n",
    "Please refer to the license in this repo for information on redistribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
